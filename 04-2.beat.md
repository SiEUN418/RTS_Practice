# Beat Exmples

## 1. Filebeat
### Install filebeat
 - 다양한 설치방법이 있지만 여기서는 직접 다운받는 방식으로 구성
```
> mkdir ~/apps
> cd ~/apps
> wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.5.2-linux-x86_64.tar.gz
> tar xvf filebeat-6.5.2-linux-x86_64.tar.gz
> cd filebeat-6.5.2-linux-x86_64
```

### configure filebeat
 - 특정 디렉토리에 있는 파일을 읽어와서 다른 디렉토리에 json 포맷으로 저장한다.

```yml
filebeat.inputs:
- type: log
  paths:
    - /home/rts/apps/sw/filebeat-6.5.2-linux-x86_64/*.yml

output.file:
  path: "/home/rts/apps/sw/filebeat-5.2.2-linux-x86_64/test"
  codec.format:
    string: '%{[message]}'
```


### run filebeat

```
> ./filebeat -e -c logfile.yml -d "publish"
```
- 정상적으로 실행되었다면, yml파일의 내용을 읽어와서
- /home/rts/apps/filebeat-5.2.2-linux-x86_64/test 아래에 filebeat이라는 파일명으로 저장
- 해당 파일을 읽어보면 아래와 같은 방식으로 저장되어 있다. (codec.format을 별도로 지정하지 않으면 json으로 저장됨)
```
{"@timestamp":"2017-03-23T11:40:34.506Z","beat":{"hostname":"dev04","name":"dev04","version":"5.2.2"},"input_type":"log","message":"  # automatically rotated","offset":31886,"source":"/home/rts/apps/filebeat-5.2.2-linux-x86_64/filebeat.full.yml","type":"log"}
{"@timestamp":"2017-03-23T11:40:34.506Z","beat":{"hostname":"dev04","name":"dev04","version":"5.2.2"},"input_type":"log","message":"  #rotateeverybytes: 10485760 # = 10MB","offset":31925,"source":"/home/rts/apps/filebeat-5.2.2-linux-x86_64/filebeat.full.yml","type":"log"}
{"@timestamp":"2017-03-23T11:40:34.506Z","beat":{"hostname":"dev04","name":"dev04","version":"5.2.2"},"input_type":"log","message":"  # Number of rotated log files to keep. Oldest files will be deleted first.","offset":32003,"source":"/home/rts/apps/filebeat-5.2.2-linux-x86_64/filebeat.full.yml","type":"log"}
{"@timestamp":"2017-03-23T11:40:34.506Z","beat":{"hostname":"dev04","name":"dev04","version":"5.2.2"},"input_type":"log","message":"  #keepfiles: 7","offset":32019,"source":"/home/rts/apps/filebeat-5.2.2-linux-x86_64/filebeat.full.yml","type":"log"}
```


### Examples 01. File to Kafka
#### Create topic
```
> /usr/hdp/2.6.5.0-292/kafka/bin/kafka-topics.sh --create --zookeeper bp03:2181 --replication-factor 3 --partitions 3 --topic test
> /usr/hdp/2.6.5.0-292/kafka/bin/kafka-topics.sh --list --zookeeper test01.hadoop.com:2181,test02.hadoop.com:2181,test03.hadoop.com
> /usr/hdp/2.6.5.0-292/kafka/bin/kafka-console-consumer.sh --bootstrap-server test03:6667,test04:6667 --topic test
```

#### create filebeat config
- download log files
```
> wget https://raw.githubusercontent.com/kmindoong/hive/master/mini_pjt/card_hist_init.csv
```
- check kafka broker ip:port
```yml
filebeat.inputs:
- type: log
  paths:
    - /home/hadoop/apps/card_hist_init.csv

output.kafka:
  # initial brokers for reading cluster metadata
  hosts: ["test03:6667", "bp04:6667", "bp05:6667"]

  # message topic selection + partitioning
  topic: 'test'
  required_acks: 1
  compression: gzip
  max_message_bytes: 1000000
  codec.format:
    string: '%{[message]}'
```

#### run filebeat
```
> bin/filebeat -e -c cof.yml
```

### Examples 02. json parsing and xpack monitoring
- json 포맷의 자료구조를 그대로 활용할 경우 json.* 옵션을 활용한다.
  - json.keys_under_root : json포맷이 JSON이라는 key로 시작하는지 여부

- xpack.monitoring
  - 만약 output이 elasticsearch라면,
  - xpack.monitoring.hosts는 중복 입력하지 않는다. 
```
filebeat.inputs:
- type: log
  paths:
   - /home/freepsw_03/data/mod_twd_web_tss_twdServer11.log.*
  json.keys_under_root: false
  json.add_error_key: true
  json.message_key: log

output.elasticsearch:
  hosts: ["localhost:9200"]

xpack.monitoring:
  enabled: true
  elasticsearch:
    username: beats_system
    password: somepassword
```
